{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4fdc1cc",
   "metadata": {},
   "source": [
    "# Homework Assignment 7 - Evan Callaghan\n",
    "\n",
    "### 1. Which of the following is/are TRUE about gradient boosting trees?\n",
    "\n",
    "#### F. In gradient boosting trees, the decision trees are dependent of each other and it is a method for improving the performance by aggregating the results of several decision trees.\n",
    "\n",
    "### 2. Suppose you are given the following scenario for training and validation for gradient boosting trees. Which scenario would you choose?\n",
    "\n",
    "#### I would choose Scenario 2 with a max depth of four. Scenario 3, 4, and 5 are all examples of over-fitting the data because they have very low training errors and high validation errors. Left with Scenario 1 and 2, Scenario 2 is the clear choice because it has less validation error for only a slight increase in model complexity when increasing the depth from two to four.\n",
    "\n",
    "### 3. In this course have covered two boosting frameworks. What is the main difference between AdaBoost and Gradient Boosting?\n",
    "\n",
    "#### The main difference between the AdaBoost and Gradient Boosting frameworks is how they work to minimize the total error. AdaBoost handles miscalssifications by adjusting observation weights so the model is forced to learn how to correctly classify or predict on those observations in order to minimize the overall cost. On the other hand, Gradient Boosting finds the observations with large residuals in the previous iteration and shifts the focus of the model to minimize each individual loss.\n",
    "\n",
    "### 4. Does the gradient boosting classifier model always outperforms the random forest model?\n",
    "\n",
    "#### No, the gradient boosting classifier model does not always outperform the random forest model. Although it may be thought of as the better model, there is no mathematical proof to ensure that it will always outperform a different type of model.\n",
    "\n",
    "### 5. Which of the following ensemble learning model does not include a learning rate parameter?\n",
    "\n",
    "#### A. The Random Forest learning model does not include a learning rate parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7021734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   male  age  education  currentSmoker  cigsPerDay  BPMeds  prevalentStroke  \\\n",
       "0     1   39        4.0              0         0.0     0.0                0   \n",
       "1     0   46        2.0              0         0.0     0.0                0   \n",
       "2     1   48        1.0              1        20.0     0.0                0   \n",
       "3     0   61        3.0              1        30.0     0.0                0   \n",
       "4     0   46        3.0              1        23.0     0.0                0   \n",
       "\n",
       "   prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  heartRate  glucose  \\\n",
       "0             0         0    195.0  106.0   70.0  26.97       80.0     77.0   \n",
       "1             0         0    250.0  121.0   81.0  28.73       95.0     76.0   \n",
       "2             0         0    245.0  127.5   80.0  25.34       75.0     70.0   \n",
       "3             1         0    225.0  150.0   95.0  28.58       65.0    103.0   \n",
       "4             0         0    285.0  130.0   84.0  23.10       85.0     85.0   \n",
       "\n",
       "   TenYearCHD  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           1  \n",
       "4           0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 6. a) Using the pandas library to read the csv data file and create a data-frame called heart\n",
    "## and removing the observations with missing values\n",
    "\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import recall_score, accuracy_score\n",
    "\n",
    "## Defining the bucket\n",
    "s3 = boto3.resource('s3')\n",
    "bucket_name = 'data-445-bucket-callaghan'\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "## Defining the csv file\n",
    "file_key = 'framingham.csv'\n",
    "\n",
    "bucket_object = bucket.Object(file_key)\n",
    "file_object = bucket_object.get()\n",
    "file_content_stream = file_object.get('Body')\n",
    "\n",
    "heart = pd.read_csv(file_content_stream)\n",
    "\n",
    "## Removing observation with missing values\n",
    "heart = heart.dropna()\n",
    "\n",
    "heart.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e721ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [08:18<00:00,  4.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1: Accuracy - 0.4551229508196722    Recall - 0.8519642857142857\n",
      "Model 2: Accuracy - 0.156775956284153    Recall - 0.9925000000000002\n",
      "Model 3: Accuracy - 0.5094808743169398    Recall - 0.8035714285714285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## b) Using age, totChol, sysBP,BMI, heartRate, and glucose as the predictor variables and TenYearCHD as the target \n",
    "## variable to do the following:\n",
    "\n",
    "## Defining the input and target variables:\n",
    "X = heart[['age', 'totChol', 'sysBP', 'BMI', 'heartRate', 'glucose']]\n",
    "Y = heart['TenYearCHD']\n",
    "\n",
    "## Defining empty lists to store results\n",
    "md1_recall = []\n",
    "md1_accuracy = []\n",
    "md2_recall = []\n",
    "md2_accuracy = []\n",
    "md3_recall = []\n",
    "md3_accuracy = []\n",
    "\n",
    "\n",
    "## Repeating 100 times:\n",
    "\n",
    "for i in tqdm(range(0, 100)):\n",
    "    \n",
    "    ## Splitting the data into training and testing sets\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, stratify = Y)\n",
    "    \n",
    "    \n",
    "    ## Model 1\n",
    "    ## ---------------------------------------\n",
    "    \n",
    "    ## Building a random forest model (with 500 trees and max tree depth equal 3) \n",
    "    md1 = RandomForestClassifier(n_estimators = 500, max_depth = 3).fit(X_train, Y_train)\n",
    "    \n",
    "    ## Predicting on the test set\n",
    "    md1_preds = md1.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    ## Using 10% as cutoff value\n",
    "    md1_preds = np.where(md1_preds < 0.1, 0, 1)\n",
    "    \n",
    "    ## Reporting the accuracy and recall of the model\n",
    "    md1_recall.append(recall_score(Y_test, md1_preds))\n",
    "    md1_accuracy.append(accuracy_score(Y_test, md1_preds))\n",
    "    \n",
    "    \n",
    "    ## Model 2\n",
    "    ## ---------------------------------------\n",
    "    \n",
    "    ## Building an AdaBoost model (with 500 trees, max tree depth equal 3, and learning rate equal to 0.01)\n",
    "    md2 = AdaBoostClassifier(base_estimator = DecisionTreeClassifier(max_depth = 3), n_estimators = 500, \n",
    "                             learning_rate = 0.01).fit(X_train, Y_train)\n",
    "    \n",
    "    ## Predicting on the test set\n",
    "    md2_preds = md2.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    ## Using 10% as cutoff value\n",
    "    md2_preds = np.where(md2_preds < 0.1, 0, 1)\n",
    "    \n",
    "    ## Reporting the accuracy and recall of the model\n",
    "    md2_recall.append(recall_score(Y_test, md2_preds))\n",
    "    md2_accuracy.append(accuracy_score(Y_test, md2_preds))\n",
    "    \n",
    "    \n",
    "    ## Model 3\n",
    "    ## ---------------------------------------\n",
    "    \n",
    "    ## Building a gradient boosting model (with 500 trees, max tree depth equal 3, and learning rate equal to 0.01) \n",
    "    md3 = GradientBoostingClassifier(max_depth = 3, n_estimators = 500, learning_rate = 0.01).fit(X_train, Y_train)\n",
    "    \n",
    "    ## Predicting on the test set\n",
    "    md3_preds = md3.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    ## Using 10% as cutoff value\n",
    "    md3_preds = np.where(md3_preds < 0.1, 0, 1)\n",
    "    \n",
    "    ## Reporting the accuracy and recall of the model\n",
    "    md3_recall.append(recall_score(Y_test, md3_preds))\n",
    "    md3_accuracy.append(accuracy_score(Y_test, md3_preds))\n",
    "    \n",
    "    \n",
    "## Reporting the average accuracy and average recall for each model\n",
    "print('Model 1: Accuracy -', np.mean(md1_accuracy), '   Recall -', np.mean(md1_recall))\n",
    "print('Model 2: Accuracy -', np.mean(md2_accuracy), '   Recall -', np.mean(md2_recall)) \n",
    "print('Model 3: Accuracy -', np.mean(md3_accuracy), '   Recall -', np.mean(md3_recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d985146",
   "metadata": {},
   "outputs": [],
   "source": [
    "## c) Assuming that the ideal model needs to have a minimum accuracy and recall equal to 80%, \n",
    "## the best model from part (b) does not meet this requirement. I would try to tune the number \n",
    "## of trees, the learning rate, and the cut-off value in order for the model to reach the \n",
    "## minimum requirements. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
